import speech_recognition as sr
import pyttsx3
import threading
import queue
import time
import os
from vosk import Model, KaldiRecognizer
import json
from sentence_transformers import SentenceTransformer, util

# Initialize TTS engine
os.environ["PYTTSX3_BACKEND"] = "espeak"
tts_engine = pyttsx3.init()
tts_engine.setProperty('rate', 150)
tts_engine.setProperty('voice', 'english')

# Queue and flags
speech_queue = queue.Queue()
stop_speaking = threading.Event()
speaking = threading.Event()
conversation_history = []

# Microphone index
MIC_INDEX = 0

# List microphones
for index, name in enumerate(sr.Microphone.list_microphone_names()):
    print(f"{index}: {name}")

# Initialize Vosk model
if not os.path.exists("vosk-model-small-en-us-0.15"):
    print("Please download Vosk model 'vosk-model-small-en-us-0.15' from https://alphacephei.com/vosk/models")
    exit(1)
vosk_model = Model("vosk-model-small-en-us-0.15")

# Initialize NLP model
try:
    nlp = SentenceTransformer('all-MiniLM-L6-v2')
except Exception as e:
    print(f"Error loading NLP model: {e}")
    nlp = None

def recognize_speech(timeout=0.05, phrase_time_limit=5, is_activation=False, is_question=False):
    r = sr.Recognizer()
    with sr.Microphone(device_index=MIC_INDEX) as source:
        r.dynamic_energy_threshold = True
        r.adjust_for_ambient_noise(source, duration=1)
        try:
            effective_timeout = 1.0 if is_activation else (0.5 if is_question else timeout)
            audio = r.listen(source, timeout=effective_timeout, phrase_time_limit=phrase_time_limit)
            recognizer = KaldiRecognizer(vosk_model, source.sample_rate)
            recognizer.AcceptWaveform(audio.get_wav_data())
            result = json.loads(recognizer.Result())
            return result.get("text", "").lower()
        except (sr.WaitTimeoutError, sr.UnknownValueError):
            return None
        except sr.RequestError as e:
            print(f"Speech recognition error: {e}")
            return None

def recognize_question():
    r = sr.Recognizer()
    full_text = []
    silence_timeout = 2.0
    max_total_duration = 20
    with sr.Microphone(device_index=MIC_INDEX) as source:
        r.dynamic_energy_threshold = True
        r.pause_threshold = silence_timeout
        r.adjust_for_ambient_noise(source, duration=1)
        start_time = time.time()
        print("Recording speech...")
        while time.time() - start_time < max_total_duration:
            try:
                audio = r.listen(source, timeout=3, phrase_time_limit=10)
                recognizer = KaldiRecognizer(vosk_model, source.sample_rate)
                recognizer.AcceptWaveform(audio.get_wav_data())
                result = json.loads(recognizer.Result())
                text = result.get("text", "").lower()
                if text:
                    full_text.append(text)
                    print(f"Captured chunk: {text}")
            except sr.WaitTimeoutError:
                break
        final_text = " ".join(full_text).strip()
        return final_text if final_text else None

def process_with_local_nlp(text):
    try:
        if nlp is None:
            return "Local NLP model not available."
        context = ", ".join(conversation_history[-10:]) if conversation_history else "No prior context."
        if "study" not in text.lower() and "productivity" not in text.lower():
            return "please don’t waste your future, study"
        sentences = [context, text]
        embeddings = nlp.encode(sentences)
        similarity = util.cos_sim(embeddings[0], embeddings[1])
        response = f"Related to context with similarity {similarity.item():.2f}" if similarity > 0.5 else "Sorry, I can’t answer that."
        if not all(c.isascii() for c in text):
            return "I only support English for now."
        return response
    except Exception as e:
        print(f"NLP processing error: {e}")
        return "Sorry, I can’t answer that right now."

def speak_text(text):
    global tts_engine
    if stop_speaking.is_set():
        return
    speaking.set()
    try:
        if not tts_engine._inLoop:
            tts_engine = pyttsx3.init()
            tts_engine.setProperty('rate', 150)
            tts_engine.setProperty('voice', 'english')
        tts_engine.say(text)
        tts_engine.runAndWait()
    except Exception as e:
        print(f"TTS error: {e}")
        try:
            tts_engine = pyttsx3.init()
            tts_engine.setProperty('rate', 150)
            tts_engine.setProperty('voice', 'english')
        except Exception as e:
            print(f"TTS reinitialization error: {e}")
    finally:
        speaking.clear()

def listen_for_activation():
    global tts_engine
    activation_phrases = ["hey steve", "steve", "hi steve"]
    while True:
        print("Listening for activation...")
        recognized_text = recognize_speech(timeout=0.05, phrase_time_limit=5, is_activation=True)
        if recognized_text and any(phrase in recognized_text for phrase in activation_phrases):
            print(f"You: {recognized_text}")
            stop_speaking.set()
            try:
                tts_engine.stop()
            except Exception as e:
                print(f"TTS stop error: {e}")
            stop_speaking.clear()
            while True:
                print("Listening for questions...")
                question_text = recognize_question()
                if question_text:
                    print(f"You: {question_text}")
                    ai_response = process_with_local_nlp(question_text)
                    print(f"AI: {ai_response}")
                    conversation_history.extend([f"Q: {question_text}", f"A: {ai_response}"])
                    if len(conversation_history) > 10:
                        conversation_history[:] = conversation_history[-10:]
                    speak_thread = threading.Thread(target=speak_text, args=(ai_response,))
                    speak_thread.start()
                    while speak_thread.is_alive():
                        interrupt_text = recognize_speech(timeout=0.05, phrase_time_limit=5, is_activation=True)
                        if interrupt_text and any(phrase in interrupt_text for phrase in activation_phrases):
                            stop_speaking.set()
                            try:
                                tts_engine.stop()
                            except Exception as e:
                                print(f"TTS stop error: {e}")
                            speak_thread.join(timeout=0.5)
                            stop_speaking.clear()
                            try:
                                tts_engine.endLoop()
                            except Exception:
                                pass
                            try:
                                tts_engine = pyttsx3.init()
                                tts_engine.setProperty('rate', 150)
                                tts_engine.setProperty('voice', 'english')
                            except Exception as e:
                                print(f"TTS reinitialization error: {e}")
                            break
                else:
                    continue

if __name__ == "__main__":
    os.environ["ALSA_LOG_LEVEL"] = "0"
    try:
        listen_thread = threading.Thread(target=listen_for_activation, daemon=True)
        listen_thread.start()
        while True:
            time.sleep(1)
    except KeyboardInterrupt:
        print("Shutting down...")
        stop_speaking.set()
        try:
            tts_engine.stop()
        except Exception as e:
            print(f"TTS stop error: {e}")
